{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff2f0a12-e6c1-43f3-96df-813f043cafcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['False advertising: If you search for Super Saver shipping this advertisement comes up, but this product is not shipped by Amazon is does not go out with the Super Saver shipping, and the cost of shipping is nearly 20% the cost of the pants.',\n",
       " 'Don\\'t Trust the Images: Dockers are Dockers, so that\\'s not the problem. Just be sure you don\\'t trust the images if you choose to buy these via Amazon. \"Cafe,\" for example, should be \"Coffee.\" Despite the fact that the image for \"Cafe\" shows a stone or very light gray color, \"Cafe\" is actually dark brown. So the product isn\\'t defective, but IS misleading: I didn\\'t want brown pants, but that\\'s what I got.',\n",
       " 'So disappointed: I have worn these pants for years; my size is the same as always. I couldn\\'t get them on; they were so tight I couldn\\'t get the button buttoned around the waist. What is going on? These pants seemed to be cut for a skinny 25 year old, not someone who is a little on the hefty side. Further, the shipping and handling charges are just out of sight...$16.95 above and beyond the already rather pricy product. I would not recommend doing business with this seller at all. You can go to other outlets and get the same thing without the shipping and handling, and there are \"deals\" out there from major store chains. I was really disappointed in this product and the seller. Go to WalMart and get their khakis; they are very inexpensive and wear like iron.',\n",
       " 'Fantastic Book: This book is a modern retelling of Sleeping Beauty with an emphasis on the power of family to help a boy through a terrible time. It is best suited for a mature, inquisitive child. War is a reality that parents should not shy away from talking about to their children.',\n",
       " \"Disturbing: Although the images are very well rendered, they arefrightening. I am baffled about the impression this book is supposedto leave on children. This book may be picked up on the thought that it is a retold fairy tale, when it is an abstract and grim retelling of the horrors of WWII in Berlin. The most horrifying image is that of Major Kreig's big black gloves enveloping the body of the little boy. This book is NOT appropriate for younger readers. I can see how this book might be valuable for an alternative look at the war for middle schoolers or higher.\",\n",
       " 'A Taste of Italy: Longing for vicarious travel? Imagining your college days, interrupted by an Italian adventure ... which turns into one of the romantic kind? And full of the silly things that come with youth, attraction and confusion? I just wanted to add my two-cents on this item, which I found, despite brief lapses in credibility, and hoppingly gullible moments, sufficiently engaging to remind me of my love of Rome. And now I have an even greater appreciation for the breadth and depth of Italian culture and character, and the wonders of eating their special dishes. Fun and satisfying.',\n",
       " \"Perfect book for a long flight....: .... or a lazy afternoon. This book is like watching a romantic movie. It is interesting, feel good and 'tasty'. Capella has done a good job of holding the reader's interest with fun descriptions of food, chefs, Rome, locals and the Italian countryside.I happened to pick this book up at a used book store and I am glad I did. You'll like this book if you are a romantic/ a foodie/ love to travel/ love Italy and Italian food or all of the above.\",\n",
       " 'Delicious reading: I found the book to be light-hearted, fun and relatively fast-moving. True, it was predictable, but that didn\\'t detract from Capella\\'s take on the triad of Bruno, Laura and Tomasso. In fact, it was nice to see how Cappella put his spin on the Cyrano story. The descriptions of the food and the locale enhanced the story and added to the atmosphere, though at times were a \"trifle overdone\" (pun intended). The only thing that kept me from giving this a 5 was the author\\'s descriptions of the sex scenes which were at times too graphic -- too male, perhaps, like reading Playboy/Penthouse letters -- for my taste. In all, though, the book was entertaining and a fun way to occupy a few summer afternoons.',\n",
       " \"Wonderfully romantic book that sweeps you to Italy: THE FOOD OF LOVE is absolutely amazing. From page one I felt like I was in Italy, smelling the smells, seeing the sights and above all, tasting the food.This book is for those who love life in all its sensual glory, who believe in recognizing your soul mate at first sight and who think that fairy tales can come true. I devoured the book (pun intended) from start to finish. It made me appreciate food and its preparation, and we're booking a trip to Italy as soon as possible to discover some of the dishes described.What Water for Chocolate did for Mexican food, this does for Italian. There is magic in preparing food for those you love. This is a fable, a romance (in the medieval sense of the word). It's about the magic and wonder of food and love, the sensual beauty of the world.\",\n",
       " \"I just wanted to cook for my husband on those dark and stary nights...: This book is better than ANY of the great trashy historical romances I have EVER read. I love to cook; I love to eat; I love my husband. This book made a great week for all three. It was an inspiration for me to perfect a couple of things, cooking and uhmmmm. If you want to get INSPIRED too, then read this book!! I'd pair it with a couple of cooking books, like Cooking in the Nude: the one for newlyweds, Booty Food, Inter-courses, or something like that. Enjoy a great book!\",\n",
       " 'One of the best!: If you are looking for something that entertains, tells a great story, and inspires you to want to go to Italy and fall in love with someone (or with the food) this is the perfect book. I recommend it as mandatory reading for all groups I bring to Italy. All who have read it, especially women, love it.',\n",
       " 'Cameriere!: I enjoyed this book-- it was much better than the standard \"chick lit\" titles. It was a lightweight story, easy to read, and the Roman food, cooking, markets and people were fun. Didn\\'t mind the creative cursing-- how very true to \"Roman young stud\" it was! Maybe the Laura character was a bit underdeveloped, but I much prefered to read about Bruno.I liked this book SO MUCH more than \"Cooking for Mr. Latte\" - it was a fun read.',\n",
       " \"Food porn, and I mean that in the best possible way: I didn't like the ending, the characterization leave something to be desired, and the writing didn't make me think, but, oh I didn't notice any of that (Well, except for the ending) at the time, or even until substatially after it was all over. During, I read and read, bathing in the glorious food descriptions, not to mention the allure of Italy. Oh Yes!\",\n",
       " '\"Chick Lit \" for \"Foodies\": What a great read = tips on cooking,lovemaking and Italian insults. Laughed and laughed. Thanks. Looking forward to film.',\n",
       " \"Not very good....: I bought this book to read as I myself ventured the streets of Italy...and to my dismay, the book was horrible. I searched everywhere for the book here in the states, and it was sold out everywhere...and to be honest, I am not sure why! All of the characters were not very well depicted, except for Laura. The description of Rome and the other cities the book took place in where not vivid. And the plot very predictible. The addition of the mafia in the story could have also been completely taken out...there was no need for it in the book! I just can't seem to think of anything really good to say about this book...maybe the recepies at the end are good to cook?\",\n",
       " 'Do not waste your time....lousy: This is one of the worst written books I have ever read.I wish I had saved my money and my time.The book is full of superlatives. Everything is \"the best ever experienced\" again and again.The characters NEVER become embraceable. One male character is pathetic while the other is a jerk. The female lead is portrayed as perhaps innocently unaware, but is really just stupid. Her friend is promiscuous, which is all we ever really get to know of her.The writing is at a level well below that of an adult reader. But, the content could not possibly be meant for a younger reader. Very inappropriate.Not sure who would really like this book.Maybe someone who really likes descriptions of food and does not care about plot, story development, characterization or any other facets of literature.Find yourself something with a little more substance, and I think you\\'ll be much happier.',\n",
       " \"The food is sexier than the sex: This book as all about the joy of eating and cooking and love.It's a lot better when it deals with food than with love. In fact, food is not only a metaphor for love and love-making but seems a more than adequate substitute. People have virtual orgasms cooking and eating but the sex is pallid and occasionally positively unappetizing.I can see why this book has been successful but to appreciate it one has to overlook the thin characters and absurd plot, openly cribbed from Cyrano de Bergerac. The most enjoyable parts are the opening chapters. After that, the returns swiftly diminish.Still, for a plane ride, one could do worse I suppose.\",\n",
       " 'Back to basics: Generally speaking a great book if you are not familiar with management accounting and turning heaps of information into valuable reports for your top management group. No doubt about it: This book will provide the basic tools for keeping your boss happy, especially if you need a brush-up on moving averages, etc. Having vast experience with both advanced financial and non-financial analysis on various aspects of business (shipping and construction), this book was somewhat a let down in terms of ability to inspire and provide ways to improve personal skills to structure and present complex topics in an ordered and clear fashion. A nice bedtable-reader for the pre-MBA. MBAs should look elsewhere.',\n",
       " 'CASH MONEY AND NO LIMIT ARE THA SAME THANG!: THERE BEATS ARE DIFFERENT THAN NO LIMITS BUT THERE FROM THA SAME PLACE AND THERE GHETTO HOOD IS VERY CLOSE.THEY RAP JUST LIKE NO LIMIT.BUT NO LIMIT WAS FIRST AND IT WILL BE THA LAST.NO LIMIT IS STILL NUMBER1 IN EVERY WAY.',\n",
       " 'Just as trashy as garbage music comes...: I listen to every kind of music in existence, and I always give everything a chance. But now I\\'m permanently going to start ignoring every CD with a CASH MONEY record label on it. They\\'re CASH MONEY Millionaires, and why? Because they fill a CD with a bunch of horrible songs and repetitive beats. They\\'re millionaires because they repeat the words \"huh,\" \"what,\" and \"yeah\" for every 3 or 4 minute song they make. They\\'re millionaires because people who expect this kind of music to be the next BIG thing make them millionaires. Bottom line: HotBoys are garbage, and so is every other artist signed onto the Cash Money label. I will NEVER consider this good music, and I hope that this is just a passing fad because if this is what \"so-called\" hip-hop music is coming to...then I only hope it\\'s worth your money cause I ain\\'t gonna spend a penny on it.',\n",
       " 'this album is garbage,straight bfi material: cash money records is going to have to up with something a lil better than this if they plan on making it in this game.the beats where alright but the rappers a terrible.none of the have a goog flow to accomidate the beats.try again cmr.maybe next time.',\n",
       " 'I feel ya \"Ghenry187@aol\"...this CD rocks. No Limit can\\'t...: I feel ya \"Ghenry187@aol.com\"...this CD rocks. No Limit can\\'t touch Cash $ Money Records. I don\\'t know why that new Tru CD sold one million in the first place. Who cares, \\'cause I just checked the billboard charts and discovered that Juvenile sold more that two million. So they can\\'t be faded. Anyway, back to this CD. Every song on this CD rocks. My favorite song is \"Help\" by B.G. I love this CD.',\n",
       " 'save your $$$: I can\\'t believe how much this cd sucks, save yourself 17 bucks & just download the \"we on fire\" mp3 its the only decent track on the album. And if u r looking for more \"bounce\" party tracks like \"back that ass up\" too bad; u won\\'t find any here. What a rip.',\n",
       " \"PLEASE DON'T BUY THIS CD!: I was truly disappointed in this album. The beats are all overused and unoriginal. The only thing that makes this album is Young Turk. He has the hottest rap out of all the Hot Boys. If you haven't heard his freestyle, you don't know what's up. Turk is off da chains. I can't wait for his solo album to drop. Ya'll need to recognize, quit hatin' Turk.\",\n",
       " \"Worst music ever....but I love it.: I don't know if you can actually call this music. It is truly terrible. However, I love listening to it for some strange music. ... I am not normally a fan of rap music, but I laugh out loud every time I hear some of these songs. These Cash Money guys should be comedians. Except for Juvenile, since I can't understand anything he says, which is also rather funny. Don't buy it for the music, but it for the comedy.\",\n",
       " 'classic: most underrated rap group, when lil wayne actually talked real s*** besides aliens and skateboards..if u like lil Wayne u should deffinetly love this album',\n",
       " 'NO, NOT 5 STARZ 6 STARZ!: this album hea is just \"too hot\". this album is tha first album that really made me like all the songs. cash money is my favorite rap label and i like other labels too but it don\\'t get no realer than this right cha\\'. this album is just to real, i mean, every song on it just blow up. every single day when i come home from school, i just have to stop and take some time out and listen to Hot Boys \"Guerilla Warfare\". like i said in the beginning \"not 5 starz 6 starz\", if you know what i mean!',\n",
       " \"THIS IS A ONE COMPARED TO JUVENILEZ 400 DEGREEZ: ALL I WILL SAY IS THIS WAS A GREAT RELEASE WHEN I FIRST BOUGHT IT AND I WOULD HAVE GIVEN IT A FOUR, BUT AFTER HAVING HEARD JUVENILE'S 400 DEGREEZ TODAY (SEPT. 30, 1999) FOR THE FIRST TIME (NOTE: YES, I KNOW I'M LATE LISTENING TO JUVENILE'S 400 DEGREEZ) I WAS VERY DISAPPOINTED WITH MANIE FRESH AND JUVENILE. JUVENILE'S 400 DEGREEZ IS THE BEST CD SINCE SNOOPS'S DOGGYSTYLE AND DRE'S CHRONIC. BUT THIS CD IS NOTHING COMPARED TO JUVENILE'S 400 DEGREEZ! IF YOU DON'T HAVE 400 DEGREEZ, GO BUY THAT ONE INSTEAD OF THIS!\",\n",
       " \"The worst rap I ever Heard: This is what is in the dictionary under wack. I can't belive that this many people bought this (...) The hot boys are just a fad like bellbottoms. (...) If you think this is what rap is about u just plain stupid and I'm glad this hot boy stuff is almost over wit. When some of my friends play this crap in the car I just rather get out and walk.\",\n",
       " 'super hot: lil wayne and turk set the whole cd off the untamed killer seem to know how to flow. his beats are for real and i cant wait for lil wayne to come out with his solo cd']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import re\n",
    "\n",
    "# Load the .txt file\n",
    "file_path = 'train.ft.txt'\n",
    "\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    raw_reviews = [next(file).strip() for _ in range(400)]  \n",
    "    #reviews = file.readlines()\n",
    "\n",
    "def clean_review(review):\n",
    "    # Remove label (e.g., __label__2) and keep only the review text\n",
    "    review_text = re.sub(r'__label__\\d+', '', review).strip()\n",
    "    review_text = re.sub(r'\\s+', ' ', review_text)  # Remove extra spaces\n",
    "    \n",
    "    return review_text\n",
    "\n",
    "# Clean the first 5 reviews\n",
    "cleaned_reviews = [clean_review(review) for review in raw_reviews]\n",
    "\n",
    "print(len(cleaned_reviews[0:25]))\n",
    "cleaned_reviews[270:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b6b867f-73ea-4fd1-9ea0-3a6d7a012189",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "# Load the T5 tokenizer for preprocessing input data\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "\n",
    "# Prepare the input data by adding a prefix for summarization\n",
    "inputs = [\"summarize: \" + review for review in cleaned_reviews]  # Add 'summarize:' prefix to each review\n",
    "\n",
    "# Tokenize the input data, handling truncation and padding\n",
    "# This converts text into input IDs and attention masks suitable for the model\n",
    "tokenized_inputs = tokenizer(inputs, truncation=True, padding=True, return_tensors='pt')\n",
    "\n",
    "# Determine the split size for the training and validation sets (80% train, 20% validation)\n",
    "train_size = int(0.8 * len(tokenized_inputs['input_ids']))\n",
    "\n",
    "# Split the tokenized inputs into training and validation datasets\n",
    "# For training inputs, take the first 80% of the data\n",
    "train_inputs = {k: v[:train_size] for k, v in tokenized_inputs.items()}\n",
    "\n",
    "# For validation inputs, take the remaining 20% of the data\n",
    "val_inputs = {k: v[train_size:] for k, v in tokenized_inputs.items()}\n",
    "\n",
    "# model = T5ForConditionalGeneration.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c14b6fb4-85da-4d92-9f03-e6de599518c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration\n",
    "from torch.optim import AdamW\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small').to(device)\n",
    "\n",
    "# Optimizer and learning rate\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55ca1402-cc88-45b3-82d6-0a73ae4118a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "train_dataset = TensorDataset(train_inputs['input_ids'], train_inputs['attention_mask'])\n",
    "val_dataset = TensorDataset(val_inputs['input_ids'], val_inputs['attention_mask'])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "47966286-4a72-4c75-ac9d-bacb24a16614",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=3):\n",
    "    # Set the model to training mode, enabling features like dropout\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0  # Initialize total loss for the epoch\n",
    "\n",
    "        # Iterate over batches of training data from the DataLoader\n",
    "        for batch in train_loader:\n",
    "            # Move input tensors to the specified device\n",
    "            input_ids, attention_mask = [x.to(device) for x in batch]\n",
    "\n",
    "            # Zero the gradients before the backward pass (calculating the gradients of the loss function with respect to the model parameters (weights)\n",
    "            #after performing a forward pass through the network)\n",
    "            #if you don’t zero the gradients before the backward pass, the gradients from the previous batch will be added to the gradients of the current batch.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #The gradients of the loss with respect to each weight are calculated using backpropagation. These gradients essentially tell us in which direction \n",
    "            #(positive or negative) to adjust the weights to reduce the loss.\n",
    "            #For example, if increasing a certain weight makes the loss larger, the gradient will be positive, and the optimizer will reduce \n",
    "            #the value of that weight.\n",
    "\n",
    "            # Perform a forward pass: compute the model outputs\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "\n",
    "            # Get the loss value from the model's output\n",
    "            loss = outputs.loss #cross-entropy loss\n",
    "\n",
    "            #Model Output: Let's say the model predicts a distribution over words like:\n",
    "\n",
    "            #\"The\" (target word): 0.6\n",
    "            #\"dog\": 0.3\n",
    "            #\"ran\": 0.1 The correct word is \"The\", so the loss penalizes the fact that the model's confidence in predicting \"The\" was only 60% (instead of 100%).\n",
    "            #Cross-Entropy Calculation: For this word, the loss would be:\n",
    "            #−log(0.6)≈0.51\n",
    "            #This value is added to the losses from other tokens in the sequence, and the average or sum of all token losses is the final loss for that sequence.\n",
    "            #total loss is sum of losses\n",
    "\n",
    "            # Backpropagate the loss to compute gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Update the model parameters using the optimizer\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate the total loss for this epoch\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # Calculate the average loss for the epoch\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch + 1} - Loss: {avg_loss}\")  # Print the average loss for the epoch\n",
    "\n",
    "        # Validate the model on the validation dataset after each epoch\n",
    "        validate_model(model, val_loader)\n",
    "\n",
    "def validate_model(model, val_loader):\n",
    "    # Set the model to evaluation mode, disabling dropout and other training-specific features\n",
    "    model.eval()\n",
    "    total_val_loss = 0  # Initialize total validation loss\n",
    "\n",
    "    # Disable gradient calculation for validation\n",
    "    with torch.no_grad():\n",
    "        # Iterate over batches of validation data from the DataLoader\n",
    "        for batch in val_loader:\n",
    "            # Move input tensors to the specified device (e.g., GPU or CPU)\n",
    "            input_ids, attention_mask = [x.to(device) for x in batch]\n",
    "\n",
    "            # Perform a forward pass: compute the model outputs for validation\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=input_ids)\n",
    "\n",
    "            # Accumulate the total validation loss\n",
    "            total_val_loss += outputs.loss.item()\n",
    "\n",
    "    # Calculate the average validation loss\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    print(f\"Validation Loss: {avg_val_loss}\")  # Print the average validation loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "91628f95-f5a5-42fa-9310-cba7e6991d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 7.350502252578735\n",
      "Validation Loss: 7.960514068603516\n",
      "Epoch 2 - Loss: 5.589021921157837\n",
      "Validation Loss: 6.08193826675415\n",
      "Epoch 3 - Loss: 3.5920020937919617\n",
      "Validation Loss: 4.239217281341553\n",
      "Epoch 4 - Loss: 1.9119222164154053\n",
      "Validation Loss: 2.6748788356781006\n",
      "Epoch 5 - Loss: 1.046639308333397\n",
      "Validation Loss: 1.8805192708969116\n"
     ]
    }
   ],
   "source": [
    "train_model(model, train_loader, val_loader, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a32e7c8-0b08-4ddb-9149-fe2a7c5e67ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one complaint about this soundtrack is that they use guitar fretting effects in many of the songs, which I find distracting. but even if those weren't included I would still consider the collection worth it.\n"
     ]
    }
   ],
   "source": [
    "def generate_summary(review):\n",
    "    inputs = tokenizer.encode(\"summarize: \" + review, return_tensors='pt').to(device)\n",
    "    summary_ids = model.generate(inputs, max_length=50, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "# Example\n",
    "new_review = \"One of the best game music soundtracks - for a game I didn't really play: Despite the fact that I have only played a small portion of the game, the music I heard (plus the connection to Chrono Trigger which was great as well) led me to purchase the soundtrack, and it remains one of my favorite albums. There is an incredible mix of fun, epic, and emotional songs. Those sad and beautiful tracks I especially like, as there's not too many of those kinds of songs in my other video game soundtracks. I must admit that one of the songs (Life-A Distant Promise) has brought tears to my eyes on many occasions.My one complaint about this soundtrack is that they use guitar fretting effects in many of the songs, which I find distracting. But even if those weren't included I would still consider the collection worth it.\"\n",
    "print(generate_summary(new_review))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c39dfa68-73d2-4ced-8c06-7a51ae9d8651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': Score(precision=0.25, recall=0.3333333333333333, fmeasure=0.28571428571428575), 'rougeL': Score(precision=0.16666666666666666, recall=0.2222222222222222, fmeasure=0.1904761904761905)}\n"
     ]
    }
   ],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n",
    "reference = \"I have only played a small portion of the game but the music i heard made it worth purchasing and it remains one of my favorite albums.\"\n",
    "summary = generate_summary(new_review)\n",
    "scores = scorer.score(reference, summary)\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafb5081-e09b-432e-a5a0-d3c08f55105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model = torch.quantization.quantize_dynamic(\n",
    "    model, {torch.nn.Linear}, dtype=torch.qint8\n",
    ")\n",
    "\n",
    "import torch.onnx\n",
    "\n",
    "dummy_input = torch.randn(1, 512).to(device)\n",
    "torch.onnx.export(quantized_model, dummy_input, \"t5_model.onnx\")\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/summarize', methods=['POST'])\n",
    "def summarize():\n",
    "    data = request.get_json()\n",
    "    review = data['review']\n",
    "    summary = generate_summary(review)\n",
    "    return jsonify({'summary': summary})\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=5000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
